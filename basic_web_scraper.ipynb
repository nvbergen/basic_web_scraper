{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Web Scraper project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This is a **simple** web scraping program that aims to troubleshoot and solve another issue I am having with Obsidian Publish. \n",
    "See the [project charter](https://github.com/nvbergen/basic_web_scraper/blob/main/charter%20-%20basic_web_scraper.md) or just go direct to the main branch of the [repo](https://github.com/nvbergen/basic_web_scraper/tree/main) for details\n",
    "\n",
    "The successful code is at the end of the file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "Ensure that you have a subdirectory labeled `output` if you are copying this code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT stream\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prompt 1\n",
    "\n",
    "> _help me write a web scraping tool that will capture all of html from a webpage._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generated code output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_html(url):\n",
    "    try:\n",
    "        # Send a GET request to the specified URL\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Raise an error if the request was unsuccessful\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Return the HTML content of the page\n",
    "        return response.text\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "# url = \"https://example.com\"\n",
    "# html_content = fetch_html(url)\n",
    "# print(html_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "The program was not executed because I failed to specify a key requirement **output of file to local directory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 2:\n",
    "> _I would also like my output to be saved locally_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generated code output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_html(url):\n",
    "    try:\n",
    "        # Send a GET request to the specified URL\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # Raise an error if the request was unsuccessful\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Return the HTML content of the page\n",
    "        return response.text\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "def save_html_to_file(html_content, file_path):\n",
    "    try:\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(html_content)\n",
    "        print(f\"HTML content saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while saving the file: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# url = \"https://example.com\"\n",
    "# html_content = fetch_html(url)\n",
    "# if html_content:\n",
    "#     save_html_to_file(html_content, \"example_page.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "Program was **not successful**\n",
    "<br>\n",
    "The code and accompanying explanation was not useful. specifically, it was not useful because I failed to specify my requirements for the program. I also thought the script was very verbose. So I attempted another prompt in the same session. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 3.\n",
    "> _Let's start again with a different version. please make a script which will meet the following requirements._\n",
    "1. [sic] _takes a single url and gets the entire HTML tree and exports a text file to a predefined path._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generated code output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_and_save_html(url, file_path):\n",
    "    \"\"\"\n",
    "    Fetches the entire HTML content from the given URL and saves it to a text file.\n",
    "    \n",
    "    Parameters:\n",
    "    - url (str): The URL of the webpage to fetch.\n",
    "    - file_path (str): The predefined path where the HTML content should be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set up a User-Agent to mimic a real browser request\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36\"\n",
    "        }\n",
    "        \n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        \n",
    "        # Save the HTML content to the specified file path\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(response.text)\n",
    "        \n",
    "        print(f\"HTML content successfully saved to: {file_path}\")\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to fetch the HTML content. Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save the HTML content. Error: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# url = \"https://example.com\"\n",
    "# file_path = \"output/example_page.txt\"\n",
    "# fetch_and_save_html(url, file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "The code looked more inline with what I was expecting so the program was executed. \n",
    "<br>\n",
    "The result was **not successful** because the requests library do not wait for the rest of the page to load. I was expecting  a long document of html in a tree structure which was not delivered. <br> Excepted results from `test1.txt`\n",
    "<br>\n",
    "<br>\n",
    "```html\n",
    "<!doctype html><html lang=\"en\"><head><meta charset=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"/><style class=\"preload\">html,body{margin:0;height:100%}body.theme-light{background-color:#fff;color:#222}body.theme-dark{background-color:#1e1e1e;color:#dadada}.preload{padding:20px;white-space:pre-wrap;overflow-wrap:break-word}@keyframes rotate{from{transform:rotate(0)}to{transform:rotate(360deg)}}</style><base href=\"https://publish.obsidian.md\"><script defer=\"defer\" \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt 4\n",
    ">_well the output was not what I had expected. can we rewrite using beautiful soup and prettify the output to match all the correct indentations etc._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generated code output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def fetch_and_save_prettified_html(url, file_path):\n",
    "    \"\"\"\n",
    "    Fetches the entire HTML content from the given URL, formats it with BeautifulSoup,\n",
    "    and saves it to a text file with proper indentation.\n",
    "    \n",
    "    Parameters:\n",
    "    - url (str): The URL of the webpage to fetch.\n",
    "    - file_path (str): The predefined path where the formatted HTML content should be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Set up a User-Agent to mimic a real browser request\n",
    "        headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36\"\n",
    "        }\n",
    "        \n",
    "        # Send a GET request to the URL\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        \n",
    "        # Parse the HTML content with BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Use BeautifulSoup's prettify function to format the HTML\n",
    "        prettified_html = soup.prettify()\n",
    "        \n",
    "        # Save the prettified HTML content to the specified file path\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(prettified_html)\n",
    "        \n",
    "        print(f\"Prettified HTML content successfully saved to: {file_path}\")\n",
    "    \n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to fetch the HTML content. Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save the HTML content. Error: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# url = \"https://example.com\"\n",
    "# file_path = \"output/example_page.txt\"\n",
    "# fetch_and_save_prettified_html(url, file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "The results of this test looked better and had all of the proper human readable indentations (that I know of) however it is still not showing any html for any of the content that actually gets loaded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Prompt\n",
    "The gpt suggested `selenium` and using `chrome` for automation purposes. I am familiar with this tool but due to reasons I will not have any other browser available other than Safari. <br><br>\n",
    "\n",
    "To my delight, safari allows for remote automation, a setting in the advanced developer menus in the Safari settings tree. \n",
    "<br><br>\n",
    "> _this file seems to be getting html that is incomplete. when I open inspect element on my browser I see a big HTML structure the file I get contains like 4 lines why the difference?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generated code output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def fetch_and_save_prettified_html_safari(url, file_path):\n",
    "    \"\"\"\n",
    "    Fetches the complete HTML content from the given URL using Selenium with Safari (rendering JavaScript),\n",
    "    formats it with BeautifulSoup, and saves it to a text file with proper indentation.\n",
    "    \n",
    "    Parameters:\n",
    "    - url (str): The URL of the webpage to fetch.\n",
    "    - file_path (str): The predefined path where the formatted HTML content should be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize the Safari browser using the WebDriver\n",
    "        driver = webdriver.Safari()\n",
    "        \n",
    "        # Navigate to the URL\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for a few seconds to allow JavaScript to load (adjust this as needed)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Get the full HTML content after JavaScript has been executed\n",
    "        html_content = driver.page_source\n",
    "        \n",
    "        # Parse the HTML content with BeautifulSoup\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        \n",
    "        # Use BeautifulSoup's prettify function to format the HTML\n",
    "        prettified_html = soup.prettify()\n",
    "        \n",
    "        # Save the prettified HTML content to the specified file path\n",
    "        with open(file_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(prettified_html)\n",
    "        \n",
    "        print(f\"Prettified HTML content successfully saved to: {file_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        # Ensure the browser is closed\n",
    "        driver.quit()\n",
    "\n",
    "# Example usage:\n",
    "# url = \"https://example.com\"\n",
    "# file_path = \"output/example_page.txt\"\n",
    "# fetch_and_save_prettified_html_safari(url, file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prettified HTML content successfully saved to: output/standard_function.txt\n"
     ]
    }
   ],
   "source": [
    "url = \"https://notes.nickvanbergen.com/Cornell+Notes+in+Obsidian\"\n",
    "file_path = \"output/standard_function.txt\"\n",
    "fetch_and_save_prettified_html_safari(url, file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "This program was successful. The resulting HTML is over 700 lines. This assures that I have the detail i need. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
